import json
import os
import time
import traceback
import re
from flask import Flask, jsonify, request, make_response
from flask_cors import CORS
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor

# ---------------------------
# üîß AI client setup
# ---------------------------
try:
    import google.generativeai as genai
    from google.api_core.exceptions import ResourceExhausted
except Exception:
    genai = None
    ResourceExhausted = Exception  # fallback

# ---------------------------
# ‚öôÔ∏è Load environment
# ---------------------------
load_dotenv()
app = Flask(__name__)
# Explicit CORS config (allows all origins ‚Äî fine for dev; tighten in production)
CORS(app, resources={r"/*": {"origins": "*"}}, supports_credentials=True)

app.config["JSON_SORT_KEYS"] = False

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY") or os.getenv("GOOGLE_API_FALLBACK", "")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.0-flash")

if genai and GOOGLE_API_KEY:
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
        app.logger.info(f"‚úÖ Google Generative AI configured (model={GEMINI_MODEL}).")
    except Exception as e:
        app.logger.error(f"‚ùå Failed to configure Gemini API: {e}")

# ---------------------------
# ‚öôÔ∏è Global state
# ---------------------------
executor = ThreadPoolExecutor(max_workers=3)
quiz_cache = {}

# ---------------------------
# üîÅ Danh s√°ch model fallback (2.x tr·ªü l√™n)
# ---------------------------
MODELS_TO_TRY = [
    GEMINI_MODEL,
    "gemini-2.5-pro",
    "gemini-2.5-flash",
    "gemini-2.0-pro",
    "gemini-2.0-flash",
    "gemini-2.0-flash-lite",
    "gemini-2.5-flash-lite-preview-09-2025",
    "gemini-2.5-flash-native-audio-preview-09-2025",
]

# ---------------------------
# Middleware: log request for debugging
# ---------------------------
@app.before_request
def log_request_info():
    try:
        app.logger.info("----- Incoming Request -----")
        app.logger.info(f"Remote Addr: {request.remote_addr}")
        app.logger.info(f"Method: {request.method} URL: {request.url}")
        headers = {k: v for k, v in request.headers.items()}
        app.logger.info(f"Headers: {headers}")
        # Avoid logging huge bodies but log content-type and length
        app.logger.info(f"Content-Type: {request.content_type} Content-Length: {request.content_length}")
    except Exception as e:
        app.logger.warning(f"Failed to log request info: {e}")

# Ensure preflight requests (OPTIONS) return 200 quickly
@app.route("/", methods=["OPTIONS"])
@app.route("/<path:anypath>", methods=["OPTIONS"])
def handle_options(anypath=None):
    resp = make_response()
    resp.status_code = 200
    return resp

# After-request to ensure proper CORS and allow headers (helps with proxies/CDN)
@app.after_request
def add_cors_headers(response):
    response.headers.setdefault("Access-Control-Allow-Origin", "*")
    response.headers.setdefault("Access-Control-Allow-Methods", "GET, POST, OPTIONS")
    response.headers.setdefault("Access-Control-Allow-Headers", "Content-Type, Authorization, X-Requested-With, Accept")
    response.headers.setdefault("Access-Control-Expose-Headers", "Content-Type, Authorization")
    return response

# Health check route
@app.route("/healthz", methods=["GET"])
def healthz():
    return jsonify({"status": "ok"}), 200

# ---------------------------
# üß† Sinh n·ªôi dung t·ª´ AI
# ---------------------------
def generate_text(prompt, retries=2):
    if genai is None:
        raise RuntimeError("Google generative AI client not available.")

    generation_config = {
        "temperature": 0.3,
        "top_p": 0.8,
        "max_output_tokens": 1600,
        "response_mime_type": "application/json",
    }

    for attempt in range(retries):
        for model_name in MODELS_TO_TRY:
            if "1.5" in model_name:
                continue  # ‚ùå Kh√¥ng d√πng model 1.5 n·ªØa

            try:
                app.logger.info(f"üîç Trying model: {model_name}")
                model = genai.GenerativeModel(model_name)
                response = model.generate_content(prompt, generation_config=generation_config)

                text = ""
                if response and hasattr(response, "candidates") and response.candidates:
                    parts = getattr(response.candidates[0].content, "parts", [])
                    text = "".join(getattr(p, "text", "") for p in parts)

                if text.strip():
                    return text.strip()

            except ResourceExhausted:
                app.logger.warning(f"‚ö†Ô∏è Model {model_name} quota exhausted.")
                continue
            except Exception as e:
                app.logger.warning(f"‚ö†Ô∏è Model {model_name} failed: {e}")
                continue

        time.sleep(0.6)

    raise Exception("‚ùå All models failed or returned invalid data.")

# ---------------------------
# üîç Parse JSON an to√†n
# ---------------------------
def safe_parse_json(text):
    def try_load(s):
        try:
            return json.loads(s)
        except Exception:
            return None

    if not text:
        return None

    try:
        json_match = re.search(r'\{[\s\S]*\}', text)
        if not json_match:
            raise ValueError("No JSON object found.")
        clean_text = json_match.group(0).strip()

        parsed = try_load(clean_text)
        if parsed:
            return parsed

        fix_text = (
            clean_text.replace("\n", " ")
            .replace("\r", "")
            .replace(", }", "}")
            .replace(",]", "]")
            .replace("‚Äô", "'")
            .replace("‚Äú", '"')
            .replace("‚Äù", '"')
            .replace("'", '"')
        )

        parsed = try_load(fix_text)
        if parsed:
            return parsed

        first, last = fix_text.find("{"), fix_text.rfind("}")
        if first != -1 and last != -1:
            parsed = try_load(fix_text[first:last + 1])
            if parsed:
                return parsed

        raise ValueError("Could not parse cleaned JSON.")
    except Exception as e:
        app.logger.warning(f"‚ö†Ô∏è JSON parse th·∫•t b·∫°i: {e}")
        return None

# ---------------------------
# üî¢ Chu·∫©n h√≥a k√Ω hi·ªáu
# ---------------------------
def normalize_math_symbols(text: str) -> str:
    import re

    if not text or not isinstance(text, str):
        return text

    # 1Ô∏è‚É£ B·ªè k√Ω t·ª± tho√°t LaTeX: \
    text = text.replace("\\", "")

    # 2Ô∏è‚É£ Chu·∫©n h√≥a sqrt ho·∫∑c ‚àö
    text = re.sub(r"sqrt\s*\{([^}]+)\}", r"‚àö\1", text)
    text = re.sub(r"sqrt\s*\(([^)]+)\)", r"‚àö\1", text)
    text = re.sub(r"‚àö\s*\{([^}]+)\}", r"‚àö\1", text)
    text = re.sub(r"‚àö\s*\(([^)]+)\)", r"‚àö\1", text)

    # 3Ô∏è‚É£ L≈©y th·ª´a (x^2 ‚Üí x¬≤, x^3 ‚Üí x¬≥)
    text = re.sub(r"\^2\b", "¬≤", text)
    text = re.sub(r"\^3\b", "¬≥", text)
    text = re.sub(
        r"\^\{(\d)\}",
        lambda m: "¬≤" if m.group(1) == "2" else ("¬≥" if m.group(1) == "3" else f"^{m.group(1)}"),
        text
    )

    # 4Ô∏è‚É£ Thay k√Ω hi·ªáu to√°n h·ªçc ph·ªï bi·∫øn
    replacements = {
        "pi": "œÄ",
        "<=": "‚â§",
        ">=": "‚â•",
        "!=": "‚â†",
        "->": "‚Üí",
        "<-": "‚Üê",
        "inf": "‚àû",
        "theta": "Œ∏",
        "alpha": "Œ±",
        "beta": "Œ≤",
        "gamma": "Œ≥",
        "delta": "Œ¥",
        "Omega": "Œ©",
        "omega": "œâ",
    }
    for k, v in replacements.items():
        text = re.sub(rf"\b{k}\b", v, text, flags=re.IGNORECASE)

    # 5Ô∏è‚É£ H√≥a h·ªçc: CH3COOH ‚Üí CH‚ÇÉCOOH
    subscript_map = str.maketrans("0123456789", "‚ÇÄ‚ÇÅ‚ÇÇ‚ÇÉ‚ÇÑ‚ÇÖ‚ÇÜ‚Çá‚Çà‚Çâ")

    def chemical_subscripts(match):
        formula = match.group(0)
        # ch·ªâ thay s·ªë sau ch·ªØ c√°i
        return re.sub(r"(?<=[A-Za-z])(\d+)", lambda m: m.group(1).translate(subscript_map), formula)

    text = re.sub(r"\b[A-Z][A-Za-z0-9()]*\b", chemical_subscripts, text)

    # 6Ô∏è‚É£ X√≥a kho·∫£ng tr·∫Øng th·ª´a
    text = re.sub(r"\s+", " ", text)

    return text.strip()

# ---------------------------
# üß© API sinh ƒë·ªÅ tr·∫Øc nghi·ªám (b·∫£n c√≥ TTL + force_regen)
# ---------------------------
@app.route("/api/generate-quiz", methods=["POST", "OPTIONS"])
def api_generate_quiz():
    start_time = time.time()
    try:
        # Try to parse JSON more robustly
        try:
            data = request.get_json(force=False, silent=True)
            if data is None:
                # Fallback: try reading raw data as text then json loads
                raw = request.data.decode("utf-8", errors="ignore")
                data = json.loads(raw) if raw else {}
        except Exception:
            data = {}
        # If still None -> empty dict
        data = data or {}

        subject = data.get("subject", "")
        grade = str(data.get("grade", ""))
        topic = data.get("topic", "").strip()
        num_mcq = int(data.get("num_mcq", 10))
        num_tf = int(data.get("num_tf", 4))
        force_regen = bool(data.get("force_regen", False))

        CACHE_TTL = 120  # ‚è± 2 ph√∫t
        cache_key = json.dumps(
            {"subject": subject, "grade": grade, "topic": topic, "num_mcq": num_mcq, "num_tf": num_tf},
            sort_keys=True
        )

        # ‚ö° Ki·ªÉm tra cache
        cached_entry = quiz_cache.get(cache_key)
        if (
            not force_regen
            and cached_entry
            and (time.time() - cached_entry["time"] < CACHE_TTL)
        ):
            app.logger.info("‚ö° Tr·∫£ ƒë·ªÅ t·ª´ cache RAM (h·ª£p l·ªá trong TTL).")
            return jsonify(cached_entry["data"])

        # ---------------------------
        # PROMPT 1: MCQ
        # ---------------------------
        prompt_mcq = f"""
Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá, kh√¥ng markdown.
T·∫°o {num_mcq} c√¢u h·ªèi tr·∫Øc nghi·ªám nhi·ªÅu l·ª±a ch·ªçn (MCQ) cho h·ªçc sinh:
- M√¥n h·ªçc: {subject}
- L·ªõp: {grade}
- Ch·ªß ƒë·ªÅ: {topic}

ƒê·ªãnh d·∫°ng:
{{
  "questions": [
    {{
      "type": "mcq",
      "question": "...",
      "options": ["A. ...", "B. ...", "C. ...", "D. ..."],
      "answer": "A"
    }}
  ]
}}
"""

        # ---------------------------
        # PROMPT 2: True/False
        # ---------------------------
        prompt_tf = f"""
Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá, kh√¥ng markdown.
T·∫°o {num_tf} c√¢u h·ªèi d·∫°ng ƒê√∫ng/Sai cho h·ªçc sinh:
- M√¥n h·ªçc: {subject}
- L·ªõp: {grade}
- Ch·ªß ƒë·ªÅ: {topic}

ƒê·ªãnh d·∫°ng:
{{
  "questions": [
    {{
      "type": "truefalse",
      "question": "...",
      "options": ["A. ƒê√∫ng", "B. Sai"],
      "answer": "A"
    }}
  ]
}}
"""

        # üß† Sinh song song MCQ v√† True/False
        fut_mcq = executor.submit(generate_text, prompt_mcq)
        fut_tf = executor.submit(generate_text, prompt_tf)
        raw_mcq, raw_tf = fut_mcq.result(timeout=25), fut_tf.result(timeout=25)

        data_mcq = safe_parse_json(raw_mcq) or {"questions": []}
        data_tf = safe_parse_json(raw_tf) or {"questions": []}

        all_questions = data_mcq.get("questions", []) + data_tf.get("questions", [])
        expected_total = num_mcq + num_tf

        # üîß N·∫øu thi·∫øu c√¢u h·ªèi, sinh b·ªï sung
        if len(all_questions) < expected_total:
            missing = expected_total - len(all_questions)
            app.logger.warning(f"‚ö†Ô∏è Thi·∫øu {missing} c√¢u, sinh b·ªï sung.")
            prompt_fix = f"T·∫°o th√™m {missing} c√¢u h·ªèi cho {subject} l·ªõp {grade} ch·ªß ƒë·ªÅ {topic}, ƒë·ªãnh d·∫°ng JSON nh∆∞ tr∆∞·ªõc."
            extra = generate_text(prompt_fix)
            data_extra = safe_parse_json(extra)
            if data_extra and isinstance(data_extra, dict):
                all_questions += data_extra.get("questions", [])

        # üî¢ Chu·∫©n h√≥a k√Ω hi·ªáu to√°n h·ªçc
        for q in all_questions:
            for field in ["question", "answer"]:
                if field in q:
                    q[field] = normalize_math_symbols(q[field])
            if "options" in q and isinstance(q["options"], list):
                q["options"] = [normalize_math_symbols(opt) for opt in q["options"]]

        result = {"questions": all_questions[:expected_total]}

        # üíæ L∆∞u cache c√πng timestamp
        quiz_cache[cache_key] = {"data": result, "time": time.time()}

        elapsed = round((time.time() - start_time) * 1000)
        app.logger.info(f"‚úÖ Sinh ƒë·ªÅ ho√†n t·∫•t: {len(result['questions'])} c√¢u ({elapsed} ms)")
        return jsonify(result)

    # üß± B·∫Øt method kh√¥ng h·ª£p l·ªá (v√≠ d·ª• Render g·ª≠i GET)
    except werkzeug.exceptions.MethodNotAllowed:
        app.logger.warning("‚ö†Ô∏è Method not allowed on /api/generate-quiz")
        return jsonify({"error": "Method not allowed"}), 405

    # üß± B·∫Øt c√°c l·ªói kh√°c, tr√°nh l·ªô th√¥ng tin
    except Exception as e:
        app.logger.error(f"‚ùå Exception: {e}\n{traceback.format_exc()}")
        return jsonify({"error": "Internal server error"}), 500


# ---------------------------
# üöÄ Run server
# ---------------------------
if __name__ == "__main__":
    port = int(os.getenv("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
